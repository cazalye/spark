{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the RDD from the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_input = sc.textFile('data/HP.txt')\n",
    "# Split the text into words and flatten the results. Why?\n",
    "words = rdd_input.flatMap(lambda line: line.split())\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map the words in such a way, so that they can be counted later by aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_map = words.map(lambda x: (x,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply reduceByKey to complete the counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = words_map.reduceByKey(lambda a,b: a+b)\n",
    "words_count.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort them in the order of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_sorted_freq = words_count.sortBy(lambda x: x[1])\n",
    "# words_count_sorted_freq = words_count.sortBy(lambda x: -x[1]) # Descending\n",
    "words_count_sorted_freq.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the file is GoT.txt\n",
    "\n",
    "rdd_got = sc.textFile('data/GOT.txt')\n",
    "rdd_got.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning and preparation: get rid of the full stop at the end of sentences, convert everything to lowercase\n",
    "# use 'replace' function of python for replacing '.'\n",
    "rdd_got = rdd_got.map(lambda line: line.replace('.', '')).map(lambda line: line.lower())\n",
    "rdd_got.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try to calculate the frequency of the words \"per line\" instead of counting them across the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_parsed = rdd_got.map(lambda x: x.split())\n",
    "rdd_parsed.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words_in_docs(doc_record):\n",
    "    counts = {}\n",
    "    for word in doc_record:  # Looping, Why?\n",
    "        if word not in counts:\n",
    "            counts[word] = 1\n",
    "        else:\n",
    "            counts[word] += 1\n",
    "    return list(counts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_loop_counts = rdd_parsed.map(count_words_in_docs)\n",
    "rdd_loop_counts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_counts_docids = rdd_loop_counts.zipWithIndex() # Generate the positional index of each record, record ids are hard to track sometimes\n",
    "rdd_counts_docids.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Exercise: Try to calculate the frequency of the term 'csc' , \"across all\" documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be an RDD (containing 4 elements) which looks like this (Only one element shown here):\n",
    "\n",
    "    [(('csc', 'doc2'), 2),\n",
    "    ..........\n",
    "    ..........\n",
    "    ..........]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_csc = sc.parallelize([\n",
    "    ('Csc-doc1-na'),\n",
    "    ('csc-doc2-na'),\n",
    "    ('cSc-doc2-na'),\n",
    "    ('csC-doc3-na'),\n",
    "    ('csc-doc3-na'),\n",
    "    ('Csc-doc3-na'),\n",
    "    ('csc-doc4-na'),\n",
    "    ('cSc-doc4-na'),\n",
    "    ('CSC-doc4-na'),\n",
    "    ('csc-doc4-na'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Please get rid of the term 'na' after you have done the pre-processing and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_csc_parsed = rdd_csc.map(lambda x: x.lower()).map(lambda x: x.split('-'))\n",
    "rdd_csc_parsed.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_csc_relevant = rdd_csc_parsed.map(lambda x: (x[0], x[1]))\n",
    "rdd_csc_relevant.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_csc_parsed_1 = rdd_csc_relevant.map(lambda x: (x,1))\n",
    "rdd_csc_parsed_1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_csc_counted = rdd_csc_parsed_1.reduceByKey(lambda a,b: a+b)\n",
    "rdd_csc_counted.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
